Ce quâ€™on a construit 
ğŸ¯ Objectif du projet CESI

Mettre en place une application logicielle complÃ¨te, avec :

dÃ©veloppement

qualitÃ©

sÃ©curitÃ©

CI/CD

dÃ©ploiement

orchestration

ğŸ‘‰ Pas juste du code, mais un systÃ¨me industriel.

ğŸ§± Architecture finale
[ Frontend React ]
        |
        v
[ Backend Spring Boot ]
        |
        v
[ PostgreSQL ]


Le tout :

packagÃ© avec Docker

dÃ©ployable en local (Docker Compose)

dÃ©ployÃ© sur Kubernetes (Minikube)

testÃ© en CI (GitHub Actions)

2ï¸âƒ£ Tout ce quâ€™on a installÃ© (et pourquoi)
ğŸ–¥ï¸ Outils systÃ¨me
âœ” Java 17 (Eclipse Adoptium)

pour exÃ©cuter Spring Boot

Java = langage backend

ğŸ‘‰ Pourquoi Java 17 ?
Version LTS, stable, recommandÃ©e en entreprise.

âœ” Maven

outil de build Java

tÃ©lÃ©charge les dÃ©pendances

compile

lance les tests

gÃ©nÃ¨re le JAR

ğŸ‘‰ Sans Maven, impossible de faire du Spring Boot proprement.

âœ” Node.js + npm

nÃ©cessaire pour React

build du frontend

ğŸ‘‰ React = frontend moderne demandÃ© implicitement.

âœ” Docker Desktop

moteur de containers

permet :

Docker Compose

Docker build

Minikube (driver docker)

ğŸ‘‰ Docker = fondation du projet.

âœ” Minikube

Kubernetes local

dÃ©monstration de CD

orchestration rÃ©elle

ğŸ‘‰ Pas du cloud, mais mÃªme logique que production.

3ï¸âƒ£ Ce quâ€™on a dÃ©veloppÃ© (code)
ğŸ§© Backend â€“ Spring Boot

API REST

JPA (ORM) pour la DB

Flyway pour les migrations

Spring Security (auth basique)

Pourquoi JPA ?

mappe les classes Java â†” tables SQL

Ã©vite le SQL manuel

standard entreprise

Pourquoi Flyway ?

versionner la base de donnÃ©es

rejouer les migrations automatiquement

cohÃ©rence entre environnements

Pourquoi Spring Security ?

sÃ©curitÃ© = exigence CESI

protection des endpoints

auth basique suffisante pour dÃ©mo

ğŸ–¥ï¸ Frontend â€“ React

interface utilisateur

appels API vers backend

servi via Nginx en prod (container)

ğŸ‘‰ React buildÃ© â†’ fichiers statiques â†’ Nginx â†’ navigateur

4ï¸âƒ£ Docker : ce quâ€™on a VRAIMENT fait
ğŸ³ Docker = packaging

Docker transforme :

backend â†’ image

frontend â†’ image

DB â†’ image

ğŸ‘‰ Une image = application + runtime + dÃ©pendances

Pourquoi Docker ?

mÃªme comportement partout

plus de â€œÃ§a marche chez moiâ€

base de la CI/CD

ğŸ§© Docker Compose
frontend
backend
postgres


ğŸ‘‰ Sert Ã  :

lancer tout en local

tester rapidement

debug

ğŸ“Œ Docker Compose = CD locale simplifiÃ©e

5ï¸âƒ£ CI : GitHub Actions
Ce que fait la CI

Ã€ chaque push :

backend :

build Maven

tests

frontend :

npm install

build React

ğŸ‘‰ Si Ã§a passe :

le code est sain

prÃªt Ã  Ãªtre packagÃ©

ğŸ“Œ CI = vÃ©rifier, PAS dÃ©ployer

6ï¸âƒ£ Le GROS piÃ¨ge quâ€™on a eu (et pourquoi câ€™est un point fort)
âŒ ProblÃ¨me : backend qui ne dÃ©marre pas

Erreur :

no main manifest attribute

Pourquoi ?

Maven gÃ©nÃ©rait un JAR

MAIS pas un JAR exÃ©cutable

Docker faisait java -jar

Java ne trouvait pas le point dâ€™entrÃ©e

âœ… Solution

Configurer correctement :

spring-boot-maven-plugin
â†’ repackage


ğŸ‘‰ RÃ©sultat :

JAR Spring Boot exÃ©cutable

Docker OK

backend dÃ©marre

ğŸ“Œ Point trÃ¨s fort Ã  lâ€™oral : incident rÃ©el + rÃ©solution.

7ï¸âƒ£ Kubernetes (Minikube) : la CD
Pourquoi Kubernetes ?

standard entreprise

orchestration

gestion rÃ©seau

redÃ©marrage automatique

ğŸ‘‰ CESI demande une logique dâ€™hÃ©bergement, pas juste du local.

Namespace
projet-indiv


ğŸ‘‰ Sert Ã  :

isoler lâ€™application

Ã©viter les conflits

structuration pro

Services

backend-svc

frontend-svc

postgres-svc

ğŸ‘‰ Kubernetes ne parle PAS aux pods directement, mais aux services.

ProblÃ¨me rÃ©seau frontend â†’ backend

Erreur :

host not found in upstream "backend"

Pourquoi ?

Nginx pointait vers backend

En Kubernetes, le nom DNS = nom du service

Solution
proxy_pass http://backend-svc:80;


ğŸ“Œ LÃ  tu as compris :

DNS Kubernetes

service discovery

8ï¸âƒ£ Images & ErrImagePull
ProblÃ¨me
ErrImagePull

Pourquoi ?

Kubernetes cherchait une image inexistante

projet-indiv:0.0.1 â‰  images rÃ©ellement buildÃ©es

Solution

supprimer le deploy inutile (api)

utiliser les bonnes images

imagePullPolicy: IfNotPresent

9ï¸âƒ£ SÃ©curitÃ© API (auth demandÃ©e)
Pourquoi lâ€™API demandait un login ?

Spring Security activÃ©

endpoints protÃ©gÃ©s

Solution

Ajouter :

app.security.users:
  - admin / admin


ğŸ‘‰ SÃ©curitÃ© simple, claire, dÃ©montrable.

ğŸ” RÃ©sumÃ© des PROBLÃˆMES & SOLUTIONS (table mentale)
ProblÃ¨me	Cause	Solution
mvn not found	Java/Maven non installÃ©s	Installation + PATH
Docker ne dÃ©marre pas	mauvais engine	Docker Desktop Linux
backend crash	JAR non exÃ©cutable	repackage
frontend crash	mauvais DNS	backend-svc
ErrImagePull	image inexistante	nettoyer deploy
namespace not found	non crÃ©Ã©	create namespace
API protÃ©gÃ©e	security active	admin/admin
ğŸ¤ Ce que tu dois retenir pour lâ€™oral

Tu nâ€™as PAS â€œjuste suiviâ€ :

tu as mis en place une chaÃ®ne complÃ¨te

tu as rÃ©solu de vrais incidents

tu comprends maintenant chaque couche

ğŸ‘‰ Tu peux dÃ©fendre :

CI

Docker

Kubernetes

SÃ©curitÃ©

Architecture

Debug


Ce qui Ã©tait dÃ©jÃ  couvert (le cÅ“ur du projet)

Tout Ã§a, on lâ€™a bien fait et bien expliquÃ© :

Git + GitHub (repo, branches)

Backend Spring Boot (JPA, Flyway, Security)

Frontend React + Nginx

Docker (images, Dockerfile)

Docker Compose (CD locale)

CI GitHub Actions

Kubernetes / Minikube (CD orchestrÃ©e)

Namespace Kubernetes

Services, DNS, port-forward

SÃ©curitÃ© API

Debug rÃ©el (logs, ErrImagePull, CrashLoop, manifest, etc.)

ğŸ‘‰ Ã‡a suffit dÃ©jÃ  Ã  valider le bloc, clairement.

ğŸ” Les points que jâ€™ajoute pour Ãªtre exhaustif (et rassurant)
1ï¸âƒ£ Git & organisation du code (important CESI)

On lâ€™a fait, mais je le formalise :

Branches

main â†’ branche stable

develop â†’ travail courant

ğŸ‘‰ Ã‡a montre :

gestion propre du code

logique dâ€™intÃ©gration continue

Phrase oral :

Le dÃ©veloppement est rÃ©alisÃ© sur une branche dÃ©diÃ©e afin de sÃ©curiser la branche principale.

2ï¸âƒ£ GitHub Actions : mÃ©triques qualitÃ© implicites

On nâ€™a pas â€œnommÃ©â€ Ã§a comme tel, mais câ€™est bien lÃ  :

build Maven

tests backend

build frontend

ğŸ‘‰ Tu peux rattacher Ã§a Ã  :

qualitÃ©

fiabilitÃ©

prÃ©vention de dette technique

Si on te demande :

Comment tu mesures la qualitÃ© ?

Tu rÃ©ponds :

Via lâ€™automatisation des builds et tests en CI. Un build cassÃ© empÃªche toute livraison.

3ï¸âƒ£ JaCoCo (coverage)

MÃªme si on nâ€™a pas encore exploitÃ© le rapport :

JaCoCo est configurÃ©

prÃªt Ã  fournir une mÃ©trique de couverture

ğŸ‘‰ Tu peux dire :

La couverture de tests est mesurÃ©e via JaCoCo, ce qui permet dâ€™Ã©valuer la robustesse du code.

4ï¸âƒ£ Pourquoi un seul namespace

Tu lâ€™as volontairement choisi, et câ€™est dÃ©fendable.

Tu peux dire :

Pour un projet individuel et un pÃ©rimÃ¨tre limitÃ©, un seul namespace est suffisant et Ã©vite une complexitÃ© inutile.

ğŸ‘‰ TrÃ¨s bon point : simplicitÃ© maÃ®trisÃ©e.

5ï¸âƒ£ eval $(minikube docker-env) (dÃ©tail important)

On lâ€™a utilisÃ©, mais maintenant tu le comprends :

Ã§a connecte Docker au daemon Minikube

permet Ã  Kubernetes de voir les images locales

Phrase oral :

Les images Docker sont construites directement dans lâ€™environnement Minikube afin dâ€™Ã©viter un registry externe.

6ï¸âƒ£ port-forward (accÃ¨s aux services)

Tu lâ€™as fait, et câ€™est clÃ© :

Kubernetes nâ€™expose rien par dÃ©faut

port-forward = accÃ¨s contrÃ´lÃ©

ğŸ‘‰ Montre que tu comprends la sÃ©curitÃ© par dÃ©faut de Kubernetes.

7ï¸âƒ£ Kubernetes Dashboard

Tu sais maintenant :

minikube dashboard


ğŸ‘‰ Super pour montrer :

pods

services

Ã©tat du cluster


Ce que Ã§a change dâ€™avoir une VM Azure (crÃ©dit 100$)

Si tu me lâ€™avais dit dÃ¨s le dÃ©but :

On aurait pu hÃ©berger Jenkins + lâ€™app directement sur la VM dÃ¨s la phase Docker/CI, au lieu de tout faire â€œlocal onlyâ€.

On aurait pensÃ© plus tÃ´t Ã  : DNS/HTTPS, ports, firewall, logs, sauvegarde DB, et pipeline CD (push image â†’ pull sur VM).

Changer maintenant est malin, parce que :

Tu as dÃ©jÃ  un projet dockerisÃ© + k8s local (Minikube) â†’ on va juste ajouter une cible â€œVMâ€ (docker compose sur VM), et Jenkins par-dessus.

Le jury verra : CI (GitHub Actions) + CI (Jenkins) + dÃ©ploiement VM + (plus tard) CD k8s Minikube.

CÃ´tÃ© rÃ¨gles/limites Azure for Students : tu as bien un crÃ©dit 100$ et des limites de quota possibles.
Pour rester dans le budget : on choisit une petite VM burstable (sÃ©rie B) et on Ã©teint quand tu ne lâ€™utilises pas.

2) SÃ©curitÃ© demandÃ©e (JWT, hash, pas de mot de passe en clair, rate limitâ€¦)

Tu as raison : câ€™est exactement le genre de points qui font â€œTech Leadâ€.

On va mettre :

Inscription + Connexion (dÃ©mo obligatoire)

Mots de passe hashÃ©s BCrypt en base (jamais en clair)

JWT Bearer (API stateless)

Rate limit sur /api/auth/* : 20 requÃªtes / minute / IP (anti brute-force)

Bonus â€œproâ€ : sÃ©paration endpoints publics/privÃ©s, erreurs propres, et headers de sÃ©cu.

3) Front plus â€œvrai site e-commerceâ€

Oui : on passe dâ€™un front â€œminimalâ€ Ã  un front type shop :

Navbar (Catalogue / Mes commandes / Swagger)

Pages : Catalogue, Panier, Connexion, Inscription, Mes commandes (protÃ©gÃ©e)

Appels API rÃ©els, stockage JWT en localStorage, routes protÃ©gÃ©es

âœ… Nouveau ZIP prÃªt (Back JWT + Front plus beau + Rate limit + CI fix)

Je tâ€™ai prÃ©parÃ© une nouvelle version complÃ¨te du projet avec tout Ã§a intÃ©grÃ© :

Download Projet-Indiv-JWT-UI.zip

Ce que contient ce zip

Backend (Spring Boot) :

/api/auth/register + /api/auth/login (JWT)

table app_users (Flyway)

BCrypt

Rate limit Bucket4j (20/min/IP sur auth)

SecurityConfig stateless + filtre JWT

Frontend (React/Vite) :

pages Login/Register/Orders

UI plus â€œsiteâ€

Checkout qui crÃ©e une commande (si connectÃ©)

Docker :

docker-compose OK (db + backend + frontend)

Kubernetes Minikube :

manifests mis Ã  jour (env nginx + secret JWT)

GitHub Actions :

fix du job front : plus de package-lock obligatoire (Ã§a rÃ©glait ton erreur de cache)





====================================
semaine 2 
Fiche rÃ©capitulatif des modifications
1) SÃ©curitÃ© applicative (authentification + autorisations)

Objectif : rÃ©pondre au volet â€œsÃ©curitÃ© minimaleâ€ et sÃ©curiser la fonction mÃ©tier.

Ajout dâ€™une couche JWT pour lâ€™authentification :

backend/src/main/java/com/cesi/projetindiv/security/JwtService.java

Mise en place de la configuration Spring Security :

backend/src/main/java/com/cesi/projetindiv/security/SecurityConfig.java

CrÃ©ation/centralisation de la logique dâ€™authentification :

backend/src/main/java/com/cesi/projetindiv/service/AuthService.java

SÃ©curisation des routes :

endpoints publics (ex: catalogue produits)

endpoints protÃ©gÃ©s (ex: commandes + historique utilisateur)

âœ… RÃ©sultat : authentification robuste et sÃ©paration claire public/privÃ©.

2) Base de donnÃ©es (migration / persistance utilisateurs)

Objectif : fiabiliser et industrialiser la crÃ©ation du schÃ©ma.

Ajout dâ€™une migration Flyway pour la table utilisateurs :

backend/src/main/resources/db/migration/V3__create_users.sql

âœ… RÃ©sultat : base versionnÃ©e, reproductible (local/CI/VM).

3) QualitÃ© logicielle (tests : 2 types minimum)

Objectif : satisfaire lâ€™exigence â€œau moins deux types de testsâ€.

Ajout / correction dâ€™un test unitaire service layer pour la crÃ©ation de commande :

backend/src/test/java/com/cesi/projetindiv/OrderServiceTest.java

AjustÃ© pour Ãªtre compatible avec les entitÃ©s JPA (constructeur protÃ©gÃ© / pas de setters).

âœ… RÃ©sultat : tests dâ€™intÃ©gration dÃ©jÃ  prÃ©sents + tests unitaires = conformitÃ© grille.

4) CI (GitHub Actions) â€œverteâ€

Objectif : garantir build/test automatique Ã  chaque push.

Mise en place/validation du pipeline GitHub Actions :

build + tests backend (Maven)

build frontend (Node)

exÃ©cution systÃ©matique sur la branche develop

Nettoyage repo et bonnes pratiques Git :

suppression des artefacts (target/, node_modules/ si prÃ©sents)

.gitignore complet pour Ã©viter de polluer le repo

RÃ©solution de synchronisation Git propre :

git pull --rebase + gestion stash

âœ… RÃ©sultat : pipeline green et repo propre, prÃªt pour dÃ©ploiement.

5) DÃ©ploiement local (Docker + Minikube)

Objectif : prouver lâ€™exÃ©cutabilitÃ© et prÃ©parer lâ€™hÃ©bergement.

ExÃ©cution en local via docker-compose.yml (frontend + backend + postgres)

DÃ©ploiement via manifests Kubernetes (k8s/) sur Minikube

VÃ©rifications API (health + endpoints mÃ©tier)

âœ… RÃ©sultat : mÃªme application dÃ©ployable sur 2 environnements (compose / k8s).

6) Fonction mÃ©tier (pour rÃ©pondre Ã  â€œ1 fonctionnalitÃ© mÃ©tierâ€)

Objectif : centrer le rendu sur une feature mÃ©tier rÃ©elle.

Fonction mÃ©tier couverte :

Catalogue produits (public)

CrÃ©ation de commande (auth)

Historique de commandes / â€œmes commandesâ€ (auth)

âœ… RÃ©sultat : vous pouvez argumenter que lâ€™auth est un prÃ©-requis sÃ©curitÃ© au service de la fonction mÃ©tier.


FICHE RÃ‰CAPITULATIVE â€” PROJET INDIV

DÃ©ploiement, CI, sÃ©curitÃ© et hÃ©bergement cloud

1. Contexte initial

Projet individuel avec :

Backend Spring Boot

Frontend Node / SPA

Conteneurisation Docker

CI existante via GitHub Actions

Objectif supplÃ©mentaire :

HÃ©bergement cloud (Europe)

DeuxiÃ¨me couche de CI avec Jenkins

Respect des consignes : sÃ©curitÃ© minimale, CI, tests, observabilitÃ©

2. Choix dâ€™architecture
HÃ©bergement

Azure VM (West Europe)

Taille : Standard B2ms (2 vCPU, 8 Go RAM)

OS : Ubuntu 24.04 LTS

ğŸ‘‰ Choix volontairement simple et rÃ©aliste, adaptÃ© Ã  un projet Ã©tudiant / PME
(au lieu dâ€™un AKS surdimensionnÃ©).

Orchestration

Local : Docker Compose + Minikube (preuve Kubernetes)

Cloud : Docker Compose sur VM

Reverse proxy : Nginx

ğŸ‘‰ Approche prod-like sans complexitÃ© inutile.

3. Mise en place de Jenkins (2áµ‰ CI)
Jenkins dÃ©ployÃ© :

Via Docker Compose

Persistance via volume jenkins_home

Jenkins accessible en HTTP

4. ProblÃ¨mes rencontrÃ©s & solutions
ğŸ”´ ProblÃ¨me 1 â€” Jenkins ne pouvait pas cloner le repo GitHub

Erreur :

Permission denied (publickey)
error in libcrypto


Cause :

Jenkins nâ€™arrivait pas Ã  utiliser une clÃ© SSH ED25519

Mauvais format pour le client Git de Jenkins

Solution :

GÃ©nÃ©ration dâ€™une clÃ© SSH RSA 4096 bits (PEM) dÃ©diÃ©e Ã  Jenkins

Ajout de la clÃ© publique sur GitHub

Ajout de la clÃ© privÃ©e dans Jenkins Credentials

Type : SSH Username with private key

Username : git

âœ… Jenkins â†” GitHub fonctionnel

ğŸ”´ ProblÃ¨me 2 â€” Jenkinsfile refusÃ© (agent docker)

Erreur :

Invalid agent type "docker"


Cause :

Plugin Docker Pipeline manquant

Solution :

Installation du plugin Docker Pipeline

ğŸ”´ ProblÃ¨me 3 â€” docker: not found dans Jenkins

Erreur :

docker: not found


Cause :

Le conteneur Jenkins nâ€™avait pas le Docker CLI

Le plugin ne suffit pas sans le binaire

Solution :

Rebuild de lâ€™image Jenkins avec :

installation de docker-ce-cli

montage de /var/run/docker.sock

ğŸ‘‰ Jenkins peut maintenant lancer des conteneurs Docker.

ğŸ”´ ProblÃ¨me 4 â€” Ã‰chec du frontend (npm ci)

Erreur :

npm ci failed


Cause :

npm ci nÃ©cessite obligatoirement un package-lock.json

Le fichier nâ€™Ã©tait pas prÃ©sent / synchronisÃ©

Solution :

GÃ©nÃ©ration du package-lock.json en local

Commit et push dans develop

Rebase pour synchroniser avec le remote

âœ… Build frontend OK

ğŸ”´ ProblÃ¨me 5 â€” Rejets Git (non-fast-forward)

Cause :

Commits effectuÃ©s depuis plusieurs environnements (local + VM)

Branche locale en retard par rapport Ã  origin/develop

Solution :

git stash

git pull --rebase origin develop

git push

5. SÃ©curitÃ© mise en place

Authentification JWT

SÃ©curisation des accÃ¨s backend

Scan de vulnÃ©rabilitÃ©s intÃ©grÃ© dans la CI (Trivy)

ClÃ©s SSH dÃ©diÃ©es (sÃ©paration des usages)

HÃ©bergement en Europe (conformitÃ© consignes)

6. CI finale (Jenkins)

Pipeline Jenkins :

Checkout Git sÃ©curisÃ© (SSH)

Tests backend (Maven dans conteneur)

Build frontend (Node dans conteneur)

Scan de sÃ©curitÃ© (Trivy)

ğŸ‘‰ CI Ã©quivalente Ã  GitHub Actions, indÃ©pendante, reproductible.

7. Bonnes pratiques dÃ©montrÃ©es

SÃ©paration local / cloud

SÃ©paration CI GitHub / CI Jenkins

Gestion propre des secrets

DÃ©bogage mÃ©thodique (logs â†’ cause â†’ solution)

Architecture Ã©volutive (VM â†’ AKS possible plus tard)

8. DÃ©cision clÃ© Ã  justifier Ã  lâ€™oral
Pourquoi pas AKS ?

AKS non exigÃ© par le sujet

CoÃ»t et complexitÃ© non justifiÃ©s

VM + Docker Compose = choix pragmatique

â€œLâ€™objectif Ã©tait de dÃ©montrer la maÃ®trise de la CI/CD et du dÃ©ploiement sÃ©curisÃ©, pas la gestion dâ€™un cluster managÃ©.â€

9. Ã‰tat final

âœ… Application fonctionnelle

âœ… CI GitHub Actions

âœ… CI Jenkins indÃ©pendante

âœ… HÃ©bergement cloud Europe

âœ… SÃ©curitÃ© minimale respectÃ©e

âœ… Projet dÃ©fendable Ã  lâ€™oral


========================================================================================================


semaine 3 
ğŸ”¹ RÃ‰CAPITULATIF â€“ JOURNÃ‰E PROJET (INFRA / CLOUD / DEVOPS)
1ï¸âƒ£ Objectif de la journÃ©e

Lâ€™objectif Ã©tait de :

stabiliser le dÃ©ploiement cloud du projet

finaliser lâ€™architecture POC cloud-ready

prÃ©parer une migration vers le cloud natif

sÃ©curiser lâ€™application (rÃ©seau + donnÃ©es + CI)

2ï¸âƒ£ Ã‰tat initial

Application full DockerisÃ©e (frontend / backend / PostgreSQL)

CI fonctionnelle via GitHub Actions

DÃ©ploiement local et sur VM Azure

Jenkins dÃ©jÃ  utilisÃ© comme seconde chaÃ®ne de CI

Limite identifiÃ©e :

La base de donnÃ©es Ã©tait encore hÃ©bergÃ©e en conteneur (non managÃ©e).

3ï¸âƒ£ Ã‰volutions majeures rÃ©alisÃ©es aujourdâ€™hui
âœ… 3.1 DÃ©ploiement sur une VM Azure

CrÃ©ation dâ€™une VM Azure (B2ms) en Europe

AccÃ¨s sÃ©curisÃ© via SSH par clÃ©

HÃ©bergement du projet en mode IaaS

Lancement des services applicatifs via Docker Compose

â¡ï¸ IntÃ©rÃªt pÃ©dagogique : maÃ®trise du dÃ©ploiement cloud bas niveau.

âœ… 3.2 Externalisation de la base de donnÃ©es (Cloud PaaS)

CrÃ©ation dâ€™une base PostgreSQL managÃ©e Azure

Connexion sÃ©curisÃ©e :

SSL/TLS activÃ© automatiquement

Test de connexion via psql

â¡ï¸ Passage de :

PostgreSQL conteneurisÃ© â†’ PostgreSQL managÃ© (PaaS)


ğŸ¯ Point clÃ© du rapport :

SÃ©paration des responsabilitÃ©s entre application (IaaS) et donnÃ©es (PaaS)

âœ… 3.3 Adaptation de lâ€™architecture applicative

Suppression de PostgreSQL Docker

Application connectÃ©e Ã  la base cloud

Variables dâ€™environnement adaptÃ©es

Application pleinement fonctionnelle avec DB distante

â¡ï¸ Architecture dÃ©sormais cloud-compatible

âœ… 3.4 SÃ©curitÃ© & bonnes pratiques

AccÃ¨s SSH par clÃ© uniquement

Base de donnÃ©es managÃ©e (sÃ©curitÃ© native Azure)

TLS actif sur PostgreSQL

Jenkins isolÃ© (non exposÃ© publiquement)

âœ… 3.5 CI/CD (hors problÃ¨mes finaux)

CI GitHub Actions opÃ©rationnelle

Jenkins utilisÃ© comme seconde chaÃ®ne de CI

Pipeline dÃ©finie via Jenkinsfile

Jenkins exÃ©cutÃ© en conteneur Docker

ğŸ¯ Point fort acadÃ©mique :

Redondance des chaÃ®nes de CI pour fiabiliser les builds

4ï¸âƒ£ ProblÃ¨mes rencontrÃ©s & solutions (Ã  valoriser)
âŒ ProblÃ¨me 1 : Conflits de ports (8080)

Cause :

Jenkins et backend tentaient dâ€™utiliser le mÃªme port

Solution :

Jenkins dÃ©placÃ© sur 127.0.0.1:8081

Backend conservÃ© sur 8080

â¡ï¸ Gestion propre des ports en environnement partagÃ©

âŒ ProblÃ¨me 2 : CoÃ»ts Azure PostgreSQL trop Ã©levÃ©s

Cause :

Configurations par dÃ©faut trÃ¨s coÃ»teuses

RÃ©gions europÃ©ennes limitÃ©es

Solution :

Choix dâ€™un serveur flexible

Configuration minimale (Dev/Test)

Utilisation raisonnÃ©e du crÃ©dit Ã©tudiant

â¡ï¸ DÃ©marche rÃ©aliste de cloud cost management

âŒ ProblÃ¨me 3 : Perte dâ€™Ã©tat Jenkins

Cause :

RedÃ©marrage/recrÃ©ation de conteneur

Volume Jenkins non persistant

Solution :

Acceptation du reset (POC)

Reconfiguration rapide

Explication claire dans le rapport

â¡ï¸ TrÃ¨s bon cas dâ€™Ã©tude DevOps

5ï¸âƒ£ Ce qui est PERTINENT Ã€ GARDER POUR LE RAPPORT
ğŸ”¥ Ã€ mettre absolument

Migration progressive vers le cloud

Usage combinÃ© :

VM (IaaS)

PostgreSQL managÃ© (PaaS)

CI GitHub Actions + Jenkins

SÃ©curitÃ© minimale :

Authentification

TLS

Isolation rÃ©seau

Architecture cloud-ready mais non encore cloud-native

âŒ Ã€ ne PAS dÃ©tailler

GalÃ¨res de credentials Jenkins

Reset de plugins

Tentatives ratÃ©es

DÃ©tails trop bas niveau Docker

6ï¸âƒ£ Phrase clÃ© de conclusion (rapport / oral)

Tu peux conclure par :

Ce projet constitue un POC visant Ã  valider une architecture applicative et DevOps dans un contexte de migration progressive vers le cloud, en combinant des services IaaS et PaaS, tout en respectant les contraintes de sÃ©curitÃ© et de coÃ»t.


==================================================================
semaine 4 
1) DÃ©cision : repartir sur une base Jenkins saine

Constat : Jenkins Ã©tait instable (droits/credentials impossibles, sÃ©curitÃ© incohÃ©rente).

Choix : reset complet de Jenkins pour retrouver un Ã©tat reproductible.

Actions

Suppression des conteneurs Jenkins et du volume jenkins_home (reset total).

RÃ©installation dâ€™un Jenkins LTS propre sur le port 8081.

CrÃ©ation/configuration du compte admin via lâ€™assistant Jenkins.
âœ… RÃ©sultat : interface stable + menu Credentials visible.

2) Connexion de Jenkins au dÃ©pÃ´t GitHub (SSH)
Objectif

Permettre Ã  Jenkins de cloner le repo privÃ©/public de faÃ§on sÃ©curisÃ©e (sans mot de passe).

Actions

GÃ©nÃ©ration dâ€™une clÃ© SSH dÃ©diÃ©e Jenkins (jenkins_github_rsa).

Ajout de la clÃ© publique sur GitHub (Settings â†’ SSH keys).

Ajout de la clÃ© privÃ©e dans Jenkins Credentials (SSH Username with private key).

âœ… RÃ©sultat : Jenkins peut lire le dÃ©pÃ´t via SSH.

3) RÃ©solution â€œHost key verification failedâ€
ProblÃ¨me

Au premier build : Jenkins refuse GitHub car le host SSH nâ€™est pas approuvÃ©.

Solution

Ajout de github.com dans known_hosts du compte Jenkins :

ssh-keyscan github.com >> /var/jenkins_home/.ssh/known_hosts

âœ… RÃ©sultat : le clonage Git devient possible.

4) Installation des plugins nÃ©cessaires au Jenkinsfile
ProblÃ¨me

Le Jenkinsfile utilisait agent { docker { ... } } â†’ erreur :

Invalid agent type "docker"

Cause

Plugin Docker Pipeline manquant.

Solution

Installation du plugin Docker Pipeline depuis Jenkins.

âœ… RÃ©sultat : Jenkins comprend les agents Docker du pipeline.

5) ProblÃ¨me â€œdocker: not foundâ€ dans la CI
ProblÃ¨me

Le pipeline dÃ©marre mais Ã©choue dÃ¨s quâ€™il exÃ©cute Docker :

docker: not found

Cause

Le plugin Docker Pipeline â‰  Docker CLI.

Jenkins est dans un conteneur qui nâ€™a pas docker installÃ©.

Solution

CrÃ©ation dâ€™une image Jenkins custom jenkins-docker avec Docker CLI installÃ©.

Relance de Jenkins en montant le socket Docker :

-v /var/run/docker.sock:/var/run/docker.sock

âœ… RÃ©sultat : Jenkins peut lancer des containers Docker pour builder.

6) ProblÃ¨me permissions sur docker.sock
ProblÃ¨me

Docker CLI prÃ©sent, mais accÃ¨s refusÃ© :

permission denied while trying to connect to the Docker daemon socket

Cause

Lâ€™utilisateur jenkins dans le conteneur nâ€™avait pas les droits sur le socket Docker de lâ€™hÃ´te.

Solution

Ajout du conteneur Jenkins au groupe docker de lâ€™hÃ´te via --group-add <GID> (GID rÃ©cupÃ©rÃ© avec getent group docker).

âœ… RÃ©sultat : Docker fonctionne depuis Jenkins (Docker Pipeline opÃ©rationnel).

7) ProblÃ¨me Trivy (entrypoint) + correction du Jenkinsfile
ProblÃ¨me

Lâ€™Ã©tape Trivy a provoquÃ© un message type :

container started but didnâ€™t run expected command (ENTRYPOINT)

Solution

Ajustement du stage Trivy dans le Jenkinsfile pour neutraliser lâ€™entrypoint de lâ€™image (args / entrypoint).

Important : on a identifiÃ© le vrai Jenkinsfile utilisÃ© : celui du repo dans /home/azureuser/apps/Projet-Indiv/Jenkinsfile.

âœ… RÃ©sultat : correction prÃªte cÃ´tÃ© repo (reste Ã  push proprement demain).

8) Blocage Git â€œpush denied (publickey)â€ depuis la VM
ProblÃ¨me

Tu as commitÃ©, mais git push depuis la VM Ã©choue :

Permission denied (publickey)

Cause

Jenkins avait son SSH credential, mais lâ€™utilisateur VM (azureuser) nâ€™avait pas sa propre clÃ© SSH GitHub (donc push impossible depuis la VM).

DÃ©cision

On reporte la correction Git/push Ã  demain (option : HTTPS+token ou SSH key azureuser).

9) HTTPS sans DNS : mise en place dâ€™un reverse proxy Nginx avec certificat auto-signÃ©
Contexte

Tu nâ€™as pas de domaine et tu ne veux pas en acheter.

Point technique important

Letâ€™s Encrypt ne dÃ©livre pas de certificat pour une IP.

Solution possible : HTTPS auto-signÃ© (acceptable pour un rendu / POC).

Actions

GÃ©nÃ©ration dâ€™un certificat auto-signÃ© (openssl) (CN = IP publique).

Installation de Nginx.

Configuration Nginx en reverse proxy HTTPS vers Jenkins :

HTTPS â†’ Nginx:443 â†’ Jenkins:8081 (localhost)

Ouverture du port 443 dans UFW.

âœ… RÃ©sultat : Jenkins accessible en HTTPS sur lâ€™IP (avec warning navigateur normal).

ğŸ§¯ Liste des erreurs rencontrÃ©es + comment on les dÃ©passe

Impossible dâ€™ajouter des credentials

Cause : Jenkins â€œsaleâ€ / setup initial mal fait / sÃ©curitÃ© incohÃ©rente

Fix : reset complet Jenkins (containers + volume) + reconfig propre

Host key verification failed (GitHub SSH)

Cause : known_hosts manquant

Fix : ssh-keyscan github.com >> known_hosts

Invalid agent type "docker"

Cause : plugin Docker Pipeline manquant

Fix : installation plugin

docker: not found

Cause : Docker CLI absent dans conteneur Jenkins

Fix : image Jenkins custom + docker CLI + montage docker.sock

permission denied docker.sock

Cause : droits groupe docker non alignÃ©s

Fix : --group-add <gid_docker_host>

Trivy container entrypoint

Cause : comportement image Trivy vs attente Jenkins Docker agent

Fix : ajuster stage (entrypoint/args)

git push denied depuis VM

Cause : clÃ©s SSH pas configurÃ©es pour azureuser

Fix demain : SSH key azureuser OU HTTPS+token

HTTPS sans DNS

Cause : Letâ€™s Encrypt ne supporte pas IP

Fix : HTTPS auto-signÃ© + Nginx reverse proxy

ğŸ¤ Les trucs pertinents Ã  dire Ã  lâ€™oral (Tech Lead angle)
Points â€œfortsâ€ Ã  valoriser

ReproductibilitÃ© : reset Jenkins pour retrouver un Ã©tat clean et contrÃ´lÃ©.

SÃ©curitÃ© : accÃ¨s Git via SSH key dÃ©diÃ©e (pas de mot de passe).

SÃ©curitÃ© SSH : known_hosts (on ne bypass pas, on valide).

CI industrialisÃ©e : pipeline exÃ©cutÃ© dans des conteneurs (agents Docker) â†’ environnements de build identiques.

Docker in Docker (propre) : Jenkins conteneur + accÃ¨s au Docker host via socket (standard en CI).

Least privilege : gestion du groupe docker plutÃ´t que root/sudo partout.

SÃ©paration des responsabilitÃ©s : Jenkins derriÃ¨re Nginx en reverse proxy.

HTTPS mÃªme sans domaine : auto-signÃ© acceptable en POC + explication claire â€œen prod on ferait Letâ€™s Encrypt avec DNSâ€.

Phrases prÃªtes Ã  sortir

â€œJenkins a Ã©tÃ© rÃ©installÃ© proprement pour garantir un Ã©tat reproductible et Ã©viter la dÃ©rive de configuration.â€

â€œOn utilise des clÃ©s SSH dÃ©diÃ©es pour lâ€™accÃ¨s GitHub, ce qui Ã©vite toute authentification par mot de passe.â€

â€œLe pipeline sâ€™exÃ©cute dans des conteneurs Docker afin dâ€™assurer des builds identiques Ã  chaque exÃ©cution.â€

â€œJenkins Ã©tant conteneurisÃ©, on a ajoutÃ© le Docker CLI et montÃ© le socket Docker de lâ€™hÃ´te, puis alignÃ© les permissions via le groupe docker.â€

â€œSans nom de domaine, Letâ€™s Encrypt nâ€™est pas possible : on a mis en place un reverse proxy Nginx en HTTPS avec certificat auto-signÃ©, suffisant pour un POC.â€

mdp user jenkins : 04b5b3e191ed4c1484b1deadd46c715d

host pg (fqdn): projet-indiv-pg.postgres.database.azure.com


let's encrypte
faut un dns 